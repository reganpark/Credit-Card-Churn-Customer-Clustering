{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bcd9d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import f1_score, matthews_corrcoef, recall_score, make_scorer\n",
    "\n",
    "#pip install scikit-learn==1.2.2 에서 작동\n",
    "from imblearn.pipeline import Pipeline as IMBPipeline\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42726f7",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d382d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/BankChurners.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043a7b1a",
   "metadata": {},
   "source": [
    "## 편의를 위해 target 열 이탈고객의 경우 1, 유지 고객은 0으로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "617dac80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Attrition_Flag'] = df['Attrition_Flag'].map({'Existing Customer': 0, 'Attrited Customer': 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31bc006",
   "metadata": {},
   "source": [
    "## 필요없는 열 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e1acf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['CLIENTNUM','Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1',\n",
    "'Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5221e8",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65397662",
   "metadata": {},
   "source": [
    "## 1. SMOTE, ADASYN 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df430c86",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82102\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\82102\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\82102\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\82102\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\82102\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\82102\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\82102\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\82102\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\82102\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\82102\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\82102\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# 데이터 분리\n",
    "X = df.drop('Attrition_Flag', axis=1)\n",
    "y = df['Attrition_Flag']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 수치형 및 범주형 컬럼 분리\n",
    "numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "categorical_features = X_train.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# 데이터 전처리 파이프라인\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(), categorical_features)\n",
    "    ])\n",
    "\n",
    "# 매튜스 상관계수와 G-평균 계산을 위한 사용자 정의 함수\n",
    "def gmean(y_true, y_pred):\n",
    "    sensitivity = recall_score(y_true, y_pred, pos_label=1)\n",
    "    specificity = recall_score(y_true, y_pred, pos_label=0)\n",
    "    return np.sqrt(sensitivity * specificity)\n",
    "\n",
    "# Scorer 객체 생성\n",
    "scorers = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'f1': 'f1',\n",
    "    'f1_macro': make_scorer(f1_score, average='macro'),\n",
    "    'f1_weighted': make_scorer(f1_score, average='weighted'),\n",
    "    'mcc': make_scorer(matthews_corrcoef),\n",
    "    'gmean': make_scorer(gmean)\n",
    "}\n",
    "\n",
    "# 모델 정의\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42),\n",
    "    'Gradient Boosting Machine': GradientBoostingClassifier(random_state=42),\n",
    "    'XGBoost': XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "}\n",
    "\n",
    "# 증강기법 및 모델 학습 파이프라인\n",
    "results = []\n",
    "for augmenter in [SMOTE(random_state=42), ADASYN(random_state=42), None]:\n",
    "    for name, model in models.items():\n",
    "        if augmenter:\n",
    "            pipeline = IMBPipeline(steps=[('preprocessor', preprocessor),\n",
    "                                          ('augmenter', augmenter),\n",
    "                                          ('classifier', model)])\n",
    "        else:\n",
    "            pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                       ('classifier', model)])\n",
    "        \n",
    "        # 교차 검증\n",
    "        cv_results = cross_validate(pipeline, X_train, y_train, cv=5, scoring=scorers)\n",
    "        results.append({\n",
    "            'Method': augmenter.__class__.__name__ if augmenter else 'Original',\n",
    "            'Model': name,\n",
    "            'Accuracy': np.mean(cv_results['test_accuracy']),\n",
    "            'F1 Score': np.mean(cv_results['test_f1']),\n",
    "            'F1 Macro': np.mean(cv_results['test_f1_macro']),\n",
    "            'F1 Weighted': np.mean(cv_results['test_f1_weighted']),\n",
    "            'MCC': np.mean(cv_results['test_mcc']),\n",
    "            'G-Mean': np.mean(cv_results['test_gmean'])\n",
    "        })\n",
    "\n",
    "# 결과 데이터프레임 생성\n",
    "results_df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c838755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Weighted</th>\n",
       "      <th>MCC</th>\n",
       "      <th>G-Mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.851860</td>\n",
       "      <td>0.644489</td>\n",
       "      <td>0.775458</td>\n",
       "      <td>0.864633</td>\n",
       "      <td>0.582532</td>\n",
       "      <td>0.847272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.954007</td>\n",
       "      <td>0.853259</td>\n",
       "      <td>0.912994</td>\n",
       "      <td>0.953665</td>\n",
       "      <td>0.826335</td>\n",
       "      <td>0.904412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>Gradient Boosting Machine</td>\n",
       "      <td>0.955559</td>\n",
       "      <td>0.865417</td>\n",
       "      <td>0.919400</td>\n",
       "      <td>0.956157</td>\n",
       "      <td>0.839680</td>\n",
       "      <td>0.930546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SMOTE</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.971642</td>\n",
       "      <td>0.910154</td>\n",
       "      <td>0.946658</td>\n",
       "      <td>0.971514</td>\n",
       "      <td>0.893535</td>\n",
       "      <td>0.941651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADASYN</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.827028</td>\n",
       "      <td>0.617308</td>\n",
       "      <td>0.752778</td>\n",
       "      <td>0.845018</td>\n",
       "      <td>0.556988</td>\n",
       "      <td>0.845059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ADASYN</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.955982</td>\n",
       "      <td>0.859854</td>\n",
       "      <td>0.916872</td>\n",
       "      <td>0.955695</td>\n",
       "      <td>0.833997</td>\n",
       "      <td>0.909105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ADASYN</td>\n",
       "      <td>Gradient Boosting Machine</td>\n",
       "      <td>0.954007</td>\n",
       "      <td>0.863032</td>\n",
       "      <td>0.917698</td>\n",
       "      <td>0.954917</td>\n",
       "      <td>0.837012</td>\n",
       "      <td>0.934971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ADASYN</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.971360</td>\n",
       "      <td>0.908647</td>\n",
       "      <td>0.945832</td>\n",
       "      <td>0.971150</td>\n",
       "      <td>0.891938</td>\n",
       "      <td>0.938425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Original</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.905333</td>\n",
       "      <td>0.665370</td>\n",
       "      <td>0.805117</td>\n",
       "      <td>0.900268</td>\n",
       "      <td>0.618566</td>\n",
       "      <td>0.754361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Original</td>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.954148</td>\n",
       "      <td>0.843166</td>\n",
       "      <td>0.908157</td>\n",
       "      <td>0.952410</td>\n",
       "      <td>0.821296</td>\n",
       "      <td>0.873985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Original</td>\n",
       "      <td>Gradient Boosting Machine</td>\n",
       "      <td>0.965717</td>\n",
       "      <td>0.887342</td>\n",
       "      <td>0.933562</td>\n",
       "      <td>0.965033</td>\n",
       "      <td>0.868651</td>\n",
       "      <td>0.914505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Original</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.972630</td>\n",
       "      <td>0.911498</td>\n",
       "      <td>0.947655</td>\n",
       "      <td>0.972273</td>\n",
       "      <td>0.896015</td>\n",
       "      <td>0.935270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Method                      Model  Accuracy  F1 Score  F1 Macro  \\\n",
       "0      SMOTE        Logistic Regression  0.851860  0.644489  0.775458   \n",
       "1      SMOTE              Random Forest  0.954007  0.853259  0.912994   \n",
       "2      SMOTE  Gradient Boosting Machine  0.955559  0.865417  0.919400   \n",
       "3      SMOTE                    XGBoost  0.971642  0.910154  0.946658   \n",
       "4     ADASYN        Logistic Regression  0.827028  0.617308  0.752778   \n",
       "5     ADASYN              Random Forest  0.955982  0.859854  0.916872   \n",
       "6     ADASYN  Gradient Boosting Machine  0.954007  0.863032  0.917698   \n",
       "7     ADASYN                    XGBoost  0.971360  0.908647  0.945832   \n",
       "8   Original        Logistic Regression  0.905333  0.665370  0.805117   \n",
       "9   Original              Random Forest  0.954148  0.843166  0.908157   \n",
       "10  Original  Gradient Boosting Machine  0.965717  0.887342  0.933562   \n",
       "11  Original                    XGBoost  0.972630  0.911498  0.947655   \n",
       "\n",
       "    F1 Weighted       MCC    G-Mean  \n",
       "0      0.864633  0.582532  0.847272  \n",
       "1      0.953665  0.826335  0.904412  \n",
       "2      0.956157  0.839680  0.930546  \n",
       "3      0.971514  0.893535  0.941651  \n",
       "4      0.845018  0.556988  0.845059  \n",
       "5      0.955695  0.833997  0.909105  \n",
       "6      0.954917  0.837012  0.934971  \n",
       "7      0.971150  0.891938  0.938425  \n",
       "8      0.900268  0.618566  0.754361  \n",
       "9      0.952410  0.821296  0.873985  \n",
       "10     0.965033  0.868651  0.914505  \n",
       "11     0.972273  0.896015  0.935270  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccc51f2",
   "metadata": {},
   "source": [
    "> 굳이 데이터 증강할 필요가 없다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e209ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46f60f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def preprocess_and_split(df, target, test_size=0.3, random_state=42):\n",
    "    # 데이터를 훈련 데이터와 테스트 데이터로 분할\n",
    "    train_df, test_df = train_test_split(df, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    # 타겟 변수와 특성 변수 분리\n",
    "    X_train = train_df.drop(columns=[target])\n",
    "    y_train = train_df[target]\n",
    "    X_test = test_df.drop(columns=[target])\n",
    "    y_test = test_df[target]\n",
    "\n",
    "    # 범주형 변수 식별 (훈련 데이터 기준)\n",
    "    categorical_columns = X_train.select_dtypes(include=['object', 'category']).columns\n",
    "    \n",
    "    # 수치형 변수 식별 (훈련 데이터 기준)\n",
    "    numeric_columns = X_train.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    # 훈련 데이터에서 수치형 변수를 표준화\n",
    "    scaler = StandardScaler()\n",
    "    X_train[numeric_columns] = scaler.fit_transform(X_train[numeric_columns])\n",
    "    X_test[numeric_columns] = scaler.transform(X_test[numeric_columns])  # 테스트 데이터는 오직 transform만 적용\n",
    "\n",
    "    # 범주형 변수를 더미 변수로 변환\n",
    "    X_train = pd.get_dummies(X_train, columns=categorical_columns, drop_first=True)\n",
    "    X_test = pd.get_dummies(X_test, columns=categorical_columns, drop_first=True)\n",
    "\n",
    "    # 더미화 후 생기는 열의 불일치 문제 해결\n",
    "    X_train, X_test = X_train.align(X_test, join='inner', axis=1)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bedec09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = preprocess_and_split(df, 'Attrition_Flag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfbf4dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=42)\n",
    "x_sm, y_sm = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d465506e",
   "metadata": {},
   "source": [
    "## GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a86e98a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classification_report' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15744/2949222297.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_sm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'classification_report' is not defined"
     ]
    }
   ],
   "source": [
    "model_sm = GradientBoostingClassifier(random_state=42)\n",
    "model_sm.fit(x_sm, y_sm)\n",
    "y_pred = model_sm.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f16584",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_raw = GradientBoostingClassifier(random_state=42)\n",
    "model_raw.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model_raw.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e061d2b",
   "metadata": {},
   "source": [
    "## XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bd2f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85e86da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_sm = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')#colsample_bytree=0.9, learning_rate=0.2, max_depth=7)\n",
    "model_sm.fit(x_sm, y_sm)\n",
    "\n",
    "y_pred = model_sm.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02756fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_raw = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')#colsample_bytree=0.9, learning_rate=0.2, max_depth=7)\n",
    "model_raw.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model_raw.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63a0a85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90c235f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46d5787",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4174f15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
